#!/usr/bin/env python3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  Digest Bot - Writer Module
#  Copyright (c) 2025 SIRIUS Alpha
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
Atomic file writer for digest output.

Features:
- Atomic writes (temp file + rename)
- Structured digest templates
- Automatic directory creation
- Backup management
"""

import logging
import os
import shutil
from dataclasses import dataclass
from datetime import date, datetime
from pathlib import Path
from tempfile import NamedTemporaryFile
from typing import Optional

from .config import Config, get_config
from .summarizer import DigestResult

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DIGEST TEMPLATE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

DIGEST_TEMPLATE = """---
title: "Daily Digest - {date}"
generated: "{timestamp}"
provider: "{provider}"
model: "{model}"
tokens_used: {tokens_used}
generation_time_s: {generation_time:.2f}
version: "1.0"
publish_to_notion: false
publish_to_discord: false
---

# ðŸ“Š Daily Digest â€” {date}

> *Generated by Gost at {time}*

---

{content}

---

## ðŸ“ˆ Generation Metadata

| Metric | Value |
|--------|-------|
| Provider | {provider} |
| Model | {model} |
| Tokens Used | {tokens_used} |
| Generation Time | {generation_time:.2f}s |

---

*This digest was automatically generated. Please verify all recommendations against current market conditions.*
"""


MINIMAL_TEMPLATE = """---
title: "Daily Digest - {date}"
generated: "{timestamp}"
publish_to_notion: false
publish_to_discord: false
---

# ðŸ“Š Daily Digest â€” {date}

{content}

---
*Generated at {time}*
"""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WRITE RESULT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


@dataclass
class WriteResult:
    """
    Result of file write operation.

    Attributes:
        success: Whether write succeeded
        path: Path to written file
        backup_path: Path to backup if created
        error: Error message if failed
    """

    success: bool
    path: Optional[Path] = None
    backup_path: Optional[Path] = None
    error: Optional[str] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# WRITER CLASS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•


class DigestWriter:
    """
    Writes digest files with atomic operations.

    Ensures digests are written safely using
    temp file + rename pattern for atomicity.
    """

    # Output filename pattern
    FILENAME_PATTERN = "digest_{date}.md"

    def __init__(
        self,
        config: Optional[Config] = None,
        output_dir: Optional[Path] = None,
    ):
        """
        Initialize writer.

        Args:
            config: Configuration object
            output_dir: Override output directory
        """
        self.config = config or get_config()

        # Output directory
        if output_dir is not None:
            self._output_dir = output_dir
        else:
            self._output_dir = self.config.paths.output_dir / "digests"

    @property
    def output_dir(self) -> Path:
        """Get output directory, creating if needed."""
        if not self._output_dir.exists():
            self._output_dir.mkdir(parents=True, exist_ok=True)
            logger.info(f"Created digest output directory: {self._output_dir}")
        return self._output_dir

    def get_digest_path(
        self,
        target_date: Optional[date] = None,
    ) -> Path:
        """
        Get path for digest file.

        Args:
            target_date: Date for the digest

        Returns:
            Path to digest file
        """
        target = target_date or date.today()
        filename = self.FILENAME_PATTERN.format(date=target.isoformat())
        return self.output_dir / filename

    def exists(self, target_date: Optional[date] = None) -> bool:
        """
        Check if digest already exists.

        Args:
            target_date: Date to check

        Returns:
            True if digest exists
        """
        return self.get_digest_path(target_date).exists()

    def _create_backup(self, path: Path) -> Optional[Path]:
        """
        Create backup of existing file.

        Args:
            path: File to backup

        Returns:
            Backup path or None
        """
        if not path.exists():
            return None

        backup_name = f"{path.stem}.backup{path.suffix}"
        backup_path = path.parent / backup_name

        try:
            shutil.copy2(path, backup_path)
            logger.debug(f"Created backup: {backup_path}")
            return backup_path
        except Exception as e:
            logger.warning(f"Failed to create backup: {e}")
            return None

    def format_digest(
        self,
        result: DigestResult,
        target_date: Optional[date] = None,
        minimal: bool = False,
    ) -> str:
        """
        Format digest result into markdown.

        Args:
            result: Digest generation result
            target_date: Date for digest
            minimal: Use minimal template

        Returns:
            Formatted markdown string
        """
        target = target_date or date.today()
        now = datetime.now()

        # Extract metadata
        metadata = result.metadata or {}

        template = MINIMAL_TEMPLATE if minimal else DIGEST_TEMPLATE

        formatted = template.format(
            date=target.isoformat(),
            timestamp=now.isoformat(),
            time=now.strftime("%H:%M:%S"),
            content=result.content,
            provider=metadata.get("provider", "unknown"),
            model=metadata.get("model", "unknown"),
            tokens_used=metadata.get("tokens_used", 0),
            generation_time=metadata.get("generation_time", 0.0),
        )

        return formatted

    def write(
        self,
        result: DigestResult,
        target_date: Optional[date] = None,
        overwrite: bool = False,
        backup: bool = True,
    ) -> WriteResult:
        """
        Write digest to file atomically.

        Uses temp file + rename for atomicity.

        Args:
            result: Digest result to write
            target_date: Date for the digest
            overwrite: Allow overwriting existing
            backup: Create backup before overwrite

        Returns:
            WriteResult with outcome
        """
        target = target_date or date.today()
        output_path = self.get_digest_path(target)
        backup_path = None

        # Allow fallback writes to overwrite existing digest files by default
        is_fallback = bool(getattr(result, 'metadata', {}) and getattr(result, 'metadata', {}).get('fallback', False))
        if is_fallback:
            overwrite = True

        # Check existing
        if output_path.exists():
            if not overwrite:
                return WriteResult(
                    success=False,
                    path=output_path,
                    error=f"Digest already exists: {output_path}",
                )

            if backup:
                backup_path = self._create_backup(output_path)

        # Defensive validation of result object (avoid AttributeError on malformed objects)
        if not getattr(result, "success", False):
            return WriteResult(
                success=False,
                error=f"Cannot write failed result: {getattr(result, 'error', 'Result indicates failure')}",
            )

        content_val = getattr(result, "content", None)
        if not content_val or len(content_val) < 50:
            return WriteResult(
                success=False,
                error="Digest content too short or empty",
            )

        # Format content
        content = self.format_digest(result, target)

        # Write atomically
        try:
            # Create temp file in same directory (same filesystem for rename)
            temp_path = None

            # Use NamedTemporaryFile with delete=False
            with NamedTemporaryFile(
                mode="w",
                encoding="utf-8",
                suffix=".tmp",
                prefix=".digest_",
                dir=self.output_dir,
                delete=False,
            ) as tf:
                temp_path = Path(tf.name)
                tf.write(content)
                tf.flush()
                os.fsync(tf.fileno())

            # Atomic rename (on Windows, need to remove target first)
            if os.name == "nt" and output_path.exists():
                output_path.unlink()

            temp_path.rename(output_path)

            logger.info(f"Wrote digest: {output_path}")

            return WriteResult(
                success=True,
                path=output_path,
                backup_path=backup_path,
            )

        except Exception as e:
            logger.error(f"Failed to write digest: {e}")

            # Cleanup temp file if exists
            if temp_path and temp_path.exists():
                try:
                    temp_path.unlink()
                except Exception:
                    pass

            return WriteResult(
                success=False,
                error=str(e),
            )

    def write_dry_run(
        self,
        result: DigestResult,
        target_date: Optional[date] = None,
    ) -> str:
        """
        Simulate write and return formatted content.

        Args:
            result: Digest result
            target_date: Date for digest

        Returns:
            Formatted digest content
        """
        return self.format_digest(result, target_date)

    def list_digests(
        self,
        limit: int = 10,
    ) -> list[Path]:
        """
        List existing digest files.

        Args:
            limit: Maximum number to return

        Returns:
            List of digest paths, newest first
        """
        if not self.output_dir.exists():
            return []

        digests = list(self.output_dir.glob("digest_*.md"))
        digests.sort(key=lambda p: p.stat().st_mtime, reverse=True)

        return digests[:limit]

    def cleanup_old_digests(
        self,
        keep_count: int = 30,
        dry_run: bool = True,
    ) -> list[Path]:
        """
        Remove old digest files.

        Args:
            keep_count: Number of recent digests to keep
            dry_run: If True, only report what would be deleted

        Returns:
            List of deleted/would-delete paths
        """
        all_digests = list(self.output_dir.glob("digest_*.md"))
        all_digests.sort(key=lambda p: p.stat().st_mtime, reverse=True)

        to_delete = all_digests[keep_count:]

        if dry_run:
            for path in to_delete:
                logger.info(f"[DRY RUN] Would delete: {path}")
        else:
            for path in to_delete:
                try:
                    path.unlink()
                    logger.info(f"Deleted old digest: {path}")
                except Exception as e:
                    logger.warning(f"Failed to delete {path}: {e}")

        return to_delete
